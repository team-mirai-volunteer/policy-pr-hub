# ============================================================
# ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å¯¾å¿œç‰ˆ - è©³ç´°ãƒ•ãƒ©ã‚°ä»˜ãExcelå‡ºåŠ›
# ============================================================
import os, re, time, torch, pandas as pd
from tqdm import tqdm
from transformers import (
    AutoTokenizer, AutoModelForSeq2SeqLM,
    AutoModelForCausalLM, pipeline
)
from huggingface_hub import login as hf_login
from google.colab import userdata
import gc

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print("ğŸ–¥ï¸ device =", DEVICE, torch.cuda.get_device_name(0) if DEVICE == "cuda" else "")

hf_token = userdata.get("HUGGINGFACE_TOKEN")
if hf_token:
    hf_login(token=hf_token)

# ============================================================
# å…¥å‡ºåŠ›è¨­å®š
# ============================================================
IN_FILE   = "/content/drive/My Drive/Colab Notebooks/pr_labels_with_body.xlsx"
OUT_FILE = "/content/drive/My Drive/pr_labels_flagged.xlsx"  # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãŒèª­ã‚€åå‰ã«åˆã‚ã›ã‚‹
MAX_ROWS = None     # ãƒ†ã‚¹ãƒˆç”¨ã€æœ¬ç•ªã¯ None

df = pd.read_excel(IN_FILE)
if MAX_ROWS: df = df.head(MAX_ROWS)
valid = ~df["body"].isin(["error", "æœ¬æ–‡ãªã—"]) & df["body"].notna()

print(f"ğŸ“Š å‡¦ç†å¯¾è±¡: {valid.sum()}ä»¶ / å…¨{len(df)}ä»¶")

# ============================================================
# è¦ç´„ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆåŠ¹ç‡åŒ–ç‰ˆï¼‰
# ============================================================
print("â–¼ è¦ç´„ãƒ•ã‚§ãƒ¼ã‚º")
SUM_MODEL = "sonoisa/t5-base-japanese"
tok_sum   = AutoTokenizer.from_pretrained(SUM_MODEL)
model_sum = AutoModelForSeq2SeqLM.from_pretrained(
    SUM_MODEL,
    torch_dtype=torch.float16,
    device_map="auto"
)

def smart_summarize(text):
    """ã‚¹ãƒãƒ¼ãƒˆè¦ç´„ï¼ˆé‡è¦éƒ¨åˆ†ã‚’å„ªå…ˆï¼‰"""
    if len(text) <= 200:
        return text

    # é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å‘¨è¾ºã‚’æŠ½å‡º
    important_keywords = ['å•é¡Œ', 'èª²é¡Œ', 'ææ¡ˆ', 'æ„è¦‹', 'ä¸»å¼µ', 'æ‰¹åˆ¤', 'æ”¯æŒ', 'åå¯¾']
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', text)

    # å…ˆé ­éƒ¨åˆ†
    summary_parts = [text[:300]]

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å«æœ‰æ–‡ã‚’è¿½åŠ 
    for sentence in sentences:
        if any(kw in sentence for kw in important_keywords):
            summary_parts.append(sentence)
        if len('ã€‚'.join(summary_parts)) > 800:
            break

    combined = 'ã€‚'.join(summary_parts)[:1000]

    inputs = tok_sum("summarize: " + combined,
                     return_tensors="pt",
                     truncation=True, max_length=512).to(DEVICE)

    with torch.no_grad():
        ids = model_sum.generate(**inputs, max_length=80, min_length=30)

    summary = tok_sum.decode(ids[0], skip_special_tokens=True).replace("\n", " ")

    del inputs, ids
    torch.cuda.empty_cache()
    return summary

# è¦ç´„å®Ÿè¡Œ
df["summary"] = [smart_summarize(b) if ok else ""
                 for ok, b in tqdm(zip(valid, df["body"]), total=len(df))]

print("è¦ç´„å®Œäº†ã€ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—")
del model_sum, tok_sum
torch.cuda.empty_cache()
gc.collect()

# ============================================================
# ã‚¹ã‚³ã‚¢å–å¾—ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰
# ============================================================
print("â–¼ ã‚¹ã‚³ã‚¢å–å¾—ãƒ•ã‚§ãƒ¼ã‚º")
SAR_MODEL = "sbintuitions/sarashina2.2-3b-instruct-v0.1"
tok_gen = AutoTokenizer.from_pretrained(SAR_MODEL)
model_gen = AutoModelForCausalLM.from_pretrained(
    SAR_MODEL,
    torch_dtype=torch.float16,
    device_map="auto"
)
generator = pipeline("text-generation", model=model_gen, tokenizer=tok_gen)

# æ”¹è‰¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
PROMPT = """ä»¥ä¸‹ã®æ–‡ç« ã«ã¤ã„ã¦ã€2ã¤ã®è¦³ç‚¹ã§æ•°å€¤è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

æ–‡ç« : ã€Œ{text}ã€

è©•ä¾¡é …ç›®:
1. ç«‹å ´/ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆ-5ã‹ã‚‰+5ã§è©•ä¾¡ï¼‰
   -5: å¼·ãåå¯¾ãƒ»å¦å®šçš„
   -3: åå¯¾ãƒ»å¦å®šçš„
   -1: ã‚„ã‚„åå¯¾ãƒ»å¦å®šçš„
    0: ä¸­ç«‹ãƒ»ã©ã¡ã‚‰ã§ã‚‚ãªã„
   +1: ã‚„ã‚„è³›æˆãƒ»è‚¯å®šçš„
   +3: è³›æˆãƒ»è‚¯å®šçš„
   +5: å¼·ãè³›æˆãƒ»è‚¯å®šçš„

2. ä¸»å¼µã®å¼·ã•ï¼ˆ-5ã‹ã‚‰+5ã§è©•ä¾¡ï¼‰
   -5: éå¸¸ã«å¼±ã„ãƒ»æ›–æ˜§
   -3: å¼±ã„
   -1: ã‚„ã‚„å¼±ã„
    0: æ™®é€š
   +1: ã‚„ã‚„å¼·ã„
   +3: å¼·ã„
   +5: éå¸¸ã«å¼·ã„ãƒ»æ–­å®šçš„

å›ç­”ï¼ˆæ•°å€¤ã®ã¿ï¼‰:
ç«‹å ´:
å¼·ã•: """

def get_enhanced_scores(txt: str):
    """å¼·åŒ–ç‰ˆã‚¹ã‚³ã‚¢å–å¾—"""
    if not txt or len(txt.strip()) < 5:
        return 0, 0

    # ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†
    if len(txt) > 800:
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', txt)
        important = [s for s in sentences if
                    any(word in s for word in ['æ€ã†', 'è€ƒãˆã‚‹', 'ä¸»å¼µ', 'æ„è¦‹', 'æ‰¹åˆ¤', 'æ”¯æŒ', 'åå¯¾', 'å•é¡Œ'])]
        txt = 'ã€‚'.join(important[:4]) if important else txt[:800]

    prompt = PROMPT.format(text=txt)

    try:
        with torch.no_grad():
            outputs = generator(
                prompt,
                max_new_tokens=20,
                do_sample=False,
                temperature=0.0,
                pad_token_id=tok_gen.eos_token_id
            )

        generated = outputs[0]["generated_text"]
        gen_part = generated[len(prompt):].strip()

        # æ•°å€¤æŠ½å‡ºã®æ”¹è‰¯
        stance_score, assert_score = 0, 0

        # è¡Œã”ã¨ã«å‡¦ç†
        lines = [line.strip() for line in gen_part.split('\n') if line.strip()]

        for i, line in enumerate(lines[:4]):
            numbers = re.findall(r'-?\d+', line)
            if not numbers:
                continue

            num = int(numbers[0])

            # ã‚ˆã‚ŠæŸ”è»Ÿãªåˆ¤å®š
            if ('ç«‹å ´' in line or 'ã‚¹ã‚¿ãƒ³ã‚¹' in line or i == 0):
                stance_score = num
            elif ('å¼·' in line or 'ä¸»å¼µ' in line or i == 1):
                assert_score = num

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€åˆã®2ã¤ã®æ•°å€¤
        if stance_score == 0 and assert_score == 0:
            all_nums = re.findall(r'-?\d+', gen_part)
            if len(all_nums) >= 2:
                stance_score, assert_score = int(all_nums[0]), int(all_nums[1])
            elif len(all_nums) == 1:
                stance_score = int(all_nums[0])

        # ç¯„å›²åˆ¶é™
        stance_score = max(-5, min(5, stance_score))
        assert_score = max(-5, min(5, assert_score))

        return stance_score, assert_score

    except Exception as e:
        print(f"âš ï¸ ã‚¨ãƒ©ãƒ¼: {e}")
        return 0, 0

# ãƒãƒƒãƒå‡¦ç†ã§ã‚¹ã‚³ã‚¢å–å¾—
stance_vals, assert_vals = [], []

print("ã‚¹ã‚³ã‚¢å–å¾—ä¸­...")
for i, (ok, summ) in enumerate(tqdm(zip(valid, df["summary"]), total=len(df))):
    if not ok or not summ:
        stance_vals.append(0)
        assert_vals.append(0)
        continue

    s, a = get_enhanced_scores(summ)
    stance_vals.append(s)
    assert_vals.append(a)

    # é€²æ—è¡¨ç¤º
    if i % 5 == 0 and i > 0:
        print(f"  å‡¦ç†æ¸ˆã¿: {i+1}/{len(df)}, æœ€æ–°ã‚¹ã‚³ã‚¢: {s}/{a}")

    time.sleep(0.05)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–

df["stance_val"] = stance_vals
df["assert_val"] = assert_vals

# ============================================================
# ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨è©³ç´°ãƒ•ãƒ©ã‚°ä½œæˆ
# ============================================================
print("â–¼ è©³ç´°ãƒ•ãƒ©ã‚°ä½œæˆ")

def create_dashboard_flags(stance_val, assert_val, text_length=0):
    """
    ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤ºç”¨ã®è©³ç´°ãƒ•ãƒ©ã‚°
    """
    flags = {}

    # åŸºæœ¬åˆ†é¡ãƒ•ãƒ©ã‚°
    flags['positive'] = stance_val > 0
    flags['negative'] = stance_val < 0
    flags['neutral'] = stance_val == 0

    # å¼·åº¦åˆ†é¡ãƒ•ãƒ©ã‚°
    flags['strong'] = abs(stance_val) >= 3
    flags['moderate'] = 1 <= abs(stance_val) <= 2
    flags['weak'] = abs(stance_val) == 1

    # ä¸»å¼µã®å¼·ã•ãƒ•ãƒ©ã‚°
    flags['assertive'] = assert_val >= 2
    flags['mild'] = -1 <= assert_val <= 1
    flags['uncertain'] = assert_val <= -2

    # çµ„ã¿åˆã‚ã›ãƒ•ãƒ©ã‚°ï¼ˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ã®è‰²åˆ†ã‘ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ç”¨ï¼‰
    flags['strong_positive'] = stance_val >= 3 and assert_val >= 1
    flags['strong_negative'] = stance_val <= -3 and assert_val >= 1
    flags['confident_neutral'] = stance_val == 0 and assert_val >= 2
    flags['weak_positive'] = 0 < stance_val <= 2 and assert_val <= 0
    flags['weak_negative'] = -2 <= stance_val < 0 and assert_val <= 0

    # å®Ÿç”¨çš„åˆ†é¡ãƒ•ãƒ©ã‚°
    flags['attention_high'] = abs(stance_val) >= 4 or assert_val >= 4  # è¦æ³¨æ„
    flags['attention_medium'] = abs(stance_val) == 3 or assert_val == 3  # ä¸­æ³¨æ„
    flags['review_needed'] = abs(stance_val) >= 2 and assert_val <= -1  # ãƒ¬ãƒ“ãƒ¥ãƒ¼å¿…è¦
    flags['low_priority'] = abs(stance_val) <= 1 and abs(assert_val) <= 1  # ä½å„ªå…ˆåº¦

    # æ¥µç«¯ã‚±ãƒ¼ã‚¹ãƒ•ãƒ©ã‚°
    flags['extreme'] = abs(stance_val) == 5 or abs(assert_val) == 5
    flags['polarized'] = abs(stance_val) >= 4 and abs(assert_val) >= 3

    # ãƒ†ã‚­ã‚¹ãƒˆé•·è€ƒæ…®ãƒ•ãƒ©ã‚°
    if text_length > 0:
        flags['long_strong'] = text_length > 1000 and abs(stance_val) >= 3
        flags['short_strong'] = text_length <= 300 and abs(stance_val) >= 3

    return flags

# å„è¡Œã«ãƒ•ãƒ©ã‚°ã‚’é©ç”¨
print("ãƒ•ãƒ©ã‚°é©ç”¨ä¸­...")
for i, row in tqdm(df.iterrows(), total=len(df)):
    text_len = len(str(row.get("body", "")))
    flags = create_dashboard_flags(row["stance_val"], row["assert_val"], text_len)

    for flag_name, flag_value in flags.items():
        df.loc[i, f"flag_{flag_name}"] = flag_value

# ============================================================
# ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ã‚«ãƒ†ã‚´ãƒªåˆ—è¿½åŠ 
# ============================================================
def get_category(stance_val, assert_val):
    """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤ºç”¨ã‚«ãƒ†ã‚´ãƒª"""
    if abs(stance_val) >= 4:
        return "æ¥µç«¯" + ("è‚¯å®š" if stance_val > 0 else "å¦å®š")
    elif abs(stance_val) >= 3:
        return "å¼·ã„" + ("è‚¯å®š" if stance_val > 0 else "å¦å®š")
    elif abs(stance_val) >= 1:
        return "ã‚„ã‚„" + ("è‚¯å®š" if stance_val > 0 else "å¦å®š")
    else:
        return "ä¸­ç«‹"

df["category"] = [get_category(s, a) for s, a in zip(df["stance_val"], df["assert_val"])]

# ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ã®è‰²åˆ†ã‘ãƒ¬ãƒ™ãƒ«
def get_priority_level(stance_val, assert_val):
    """å„ªå…ˆåº¦ãƒ¬ãƒ™ãƒ«ï¼ˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®è‰²åˆ†ã‘ç”¨ï¼‰"""
    if abs(stance_val) >= 4 or assert_val >= 4:
        return "High"
    elif abs(stance_val) >= 3 or assert_val >= 3:
        return "Medium"
    elif abs(stance_val) >= 1 or abs(assert_val) >= 1:
        return "Low"
    else:
        return "Minimal"

df["priority"] = [get_priority_level(s, a) for s, a in zip(df["stance_val"], df["assert_val"])]

# ============================================================
# çµæœçµ±è¨ˆã¨ä¿å­˜
# ============================================================
print("\nğŸ“Š è©³ç´°çµæœçµ±è¨ˆ:")
print("=" * 50)
print(f"ã‚¹ã‚¿ãƒ³ã‚¹åˆ†å¸ƒ:")
for val in sorted(df['stance_val'].unique()):
    count = (df['stance_val'] == val).sum()
    print(f"  {val:+2d}: {count:3d}ä»¶")

print(f"\nä¸»å¼µå¼·åº¦åˆ†å¸ƒ:")
for val in sorted(df['assert_val'].unique()):
    count = (df['assert_val'] == val).sum()
    print(f"  {val:+2d}: {count:3d}ä»¶")

print(f"\nã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ:")
print(df['category'].value_counts())

print(f"\nå„ªå…ˆåº¦åˆ†å¸ƒ:")
print(df['priority'].value_counts())

print(f"\nä¸»è¦ãƒ•ãƒ©ã‚°çµ±è¨ˆ:")
flag_cols = [col for col in df.columns if col.startswith('flag_')]
for flag in ['flag_attention_high', 'flag_strong_positive', 'flag_strong_negative',
             'flag_review_needed', 'flag_extreme']:
    if flag in flag_cols:
        count = df[flag].sum()
        print(f"  {flag.replace('flag_', '')}: {count}ä»¶")

# Excelä¿å­˜
df.to_excel(OUT_FILE, index=False)
print(f"\nâœ… å®Œäº†ï¼ä¿å­˜å…ˆ: {OUT_FILE}")
print(f"ğŸ“ åˆ—æ•°: {len(df.columns)}, è¡Œæ•°: {len(df)}")

# ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
del model_gen, tok_gen, generator
torch.cuda.empty_cache()
print("ğŸ§¹ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")