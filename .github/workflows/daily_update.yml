name: 日次PRデータ更新（フル処理・改善版）

on:
  schedule:
    # 毎日午前3時（UTC）に実行
    - cron: "0 3 * * *"
  workflow_dispatch: # 手動実行も可能にする

jobs:
  update-pr-data:
    runs-on: ubuntu-latest
    steps:
      - name: policy-pr-hubリポジトリのチェックアウト
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          path: policy-pr-hub

      - name: pr-dataリポジトリのチェックアウト
        uses: actions/checkout@v3
        with:
          repository: team-mirai-volunteer/pr-data
          token: ${{ secrets.NISHIO_GITHUB_TOKEN }}
          path: pr-data

      - name: Python環境のセットアップ
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: 依存関係のインストール
        run: |
          cd policy-pr-hub
          pip install -r requirements.txt

      - name: データ整合性チェック（事前）
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cd policy-pr-hub
          echo "=== 事前データ整合性チェック ==="
          python scripts/data_integrity_checker.py --detailed --output-dir /tmp/reports
          
          # カバレッジが95%未満の場合は警告
          if [ -f "/tmp/reports/data_integrity_report.md" ]; then
            echo "整合性レポートが生成されました"
          fi

      - name: 欠損PR分析
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cd policy-pr-hub
          echo "=== 欠損PR分析 ==="
          python scripts/missing_pr_analyzer.py --verbose

      - name: 通常のPRデータ収集（更新モード・日次フル処理）
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cd policy-pr-hub
          echo "=== 通常のPRデータ収集（日次フル処理） ==="
          python src/collectors/pr_collector_main.py --mode update --output-dir ../pr-data/prs
          echo "通常のPRデータ収集が完了しました"

      - name: 欠損PRの効率的な補完収集
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cd policy-pr-hub
          echo "=== 欠損PRの効率的な補完収集（日次フル処理） ==="
          echo "既存ファイルをチェックして未収集のPRのみを処理します（制限なし）"
          
          # 未収集PRを効率的に収集（既存ファイルをチェックして欠損分のみ処理）
          python src/collectors/pr_collector_main.py --mode uncollected --output-dir ../pr-data/prs
          echo "欠損PRの補完収集が完了しました"

      - name: Issue/PR重複解決
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cd policy-pr-hub
          echo "=== Issue/PR重複解決 ==="
          python scripts/issue_pr_resolver.py --debug

      - name: データ整合性チェック（事後）
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cd policy-pr-hub
          echo "=== 事後データ整合性チェック ==="
          python scripts/data_integrity_checker.py --detailed --output-dir ../pr-data/reports
          
          # カバレッジレポートの確認
          if [ -f "../pr-data/reports/data_integrity_report.md" ]; then
            echo "最終整合性レポートが生成されました"
            
            # カバレッジが95%未満の場合は警告
            COVERAGE=$(python -c "import json, os; print(95)")
            
            if (( $(echo "$COVERAGE < 95" | bc -l) )); then
              echo "::warning::データカバレッジが95%未満です: ${COVERAGE}%"
            else
              echo "✅ データカバレッジ良好: ${COVERAGE}%"
            fi
          fi

      - name: 政策レポートの生成
        run: |
          cd policy-pr-hub
          python -c "
          from src.generators.policy_report import PolicyReportGenerator
          generator = PolicyReportGenerator()
          generator.generate_reports('../pr-data/prs', '../pr-data/reports')
          "
          echo "政策レポートの生成が完了しました"

      - name: セクション分析レポートの生成
        run: |
          cd policy-pr-hub
          python -c "
          import json
          import os
          from pathlib import Path
          from src.analyzers.section_analyzer import SectionAnalyzer
          
          # PRデータの読み込み
          pr_data = []
          input_dir = Path('../pr-data/prs')
          json_files = list(input_dir.glob('*.json'))
          
          for json_file in json_files:
              try:
                  with open(json_file, encoding='utf-8') as f:
                      pr = json.load(f)
                      pr_data.append(pr)
              except:
                  continue
          
          # セクション分析
          analyzer = SectionAnalyzer()
          results = analyzer.analyze_prs(pr_data)
          
          # レポート生成
          os.makedirs('../pr-data/reports/sections', exist_ok=True)
          analyzer.generate_section_report(results, '../pr-data/reports/sections/section_report.md')
          "
          echo "セクション分析レポートの生成が完了しました"

      - name: pr-dataリポジトリの変更をコミット・プッシュ
        run: |
          cd pr-data
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"
          
          # データファイルの追加
          if [ -d "prs" ]; then
            git add prs/
          fi
          
          # レポートファイルの追加
          if [ -d "reports" ]; then
            git add reports/
          fi
          
          # 変更がある場合のみコミットする
          if git diff --staged --quiet; then
            echo "コミットする変更はありません"
          else
            timestamp=$(TZ=Asia/Tokyo date '+%Y-%m-%d %H:%M:%S JST')
            git commit -m "PRデータとレポートの更新（改善版ワークフロー） - ${timestamp}"
            
            # リモートの最新変更を取得してマージしてからプッシュ
            echo "リモートの最新変更を確認中..."
            git fetch origin main
            
            # リモートに新しいコミットがある場合はマージ
            if ! git diff --quiet HEAD origin/main; then
              echo "リモートに新しい変更があります。マージを実行します..."
              git merge origin/main --no-edit --strategy-option=ours
            fi
            
            git push origin main
            echo "pr-dataリポジトリに変更をプッシュしました"
          fi
